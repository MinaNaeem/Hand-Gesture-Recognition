{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbrzNXKLGRMB",
        "outputId": "756085d5-c6e2-4bd6-950f-ddfb21e3e764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HuLFPJL2HDjB"
      },
      "outputs": [],
      "source": [
        "train_dir = 'D:\\DEPI\\Project\\DEPI_proj_dataset'\n",
        "test_dir = 'D:\\DEPI\\Project\\Test_set'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgdEmITCHLrZ",
        "outputId": "efb8b8b5-aece-47f3-e635-2fa77f04a0a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 23274 images belonging to 37 classes.\n",
            "Found 5807 images belonging to 37 classes.\n",
            "Found 1027 images belonging to 37 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set up ImageDataGenerators\n",
        "train_data = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "test_data = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_data.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_gen = train_data.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_gen = test_data.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OIcn6xtDHQUu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Input(shape=(224, 224, 3)),  # Input shape\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(train_gen.num_classes, activation='softmax')  # Number of classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AHh85e8WHaLv"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# # Define the model checkpoint callback\n",
        "# checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "#     'model_weights.weights.h5',  # Correct file extension\n",
        "#     save_weights_only=True,\n",
        "#     save_best_only=True,\n",
        "#     monitor='val_loss',\n",
        "#     mode='min',\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Path to save weights\n",
        "#weights_dir = '/content/drive/MyDrive/Sign Language Recognition_DEPI/weights'\n",
        "weights_path = 'model_weights.h5'\n",
        "\n",
        "# Define the model checkpoint callback to save weights\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "    weights_path,  # Full path to save the weights\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "jLFOu0W7QD8K",
        "outputId": "9c57aa12-8e34-4e86-9f2c-fb85e8fe8b28"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c795d51da2e9>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Clean your train, validation, and test directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mremove_corrupted_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mremove_corrupted_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mremove_corrupted_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-c795d51da2e9>\u001b[0m in \u001b[0;36mremove_corrupted_images\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mis_image_corrupted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Removed {img_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-c795d51da2e9>\u001b[0m in \u001b[0;36mis_image_corrupted\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_image_corrupted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Verify if it's an image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3440\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3442\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3444\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from PIL import Image, UnidentifiedImageError\n",
        "import os\n",
        "\n",
        "# Function to check for corrupted images\n",
        "def is_image_corrupted(img_path):\n",
        "    try:\n",
        "        img = Image.open(img_path)\n",
        "        img.verify()  # Verify if it's an image\n",
        "        return False\n",
        "    except (UnidentifiedImageError, IOError):\n",
        "        print(f\"Corrupted image: {img_path}\")\n",
        "        return True\n",
        "\n",
        "# Function to remove corrupted images from the dataset\n",
        "def remove_corrupted_images(directory):\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            img_path = os.path.join(root, file)\n",
        "            if is_image_corrupted(img_path):\n",
        "                os.remove(img_path)\n",
        "                print(f\"Removed {img_path}\")\n",
        "\n",
        "# Clean your train, validation, and test directories\n",
        "remove_corrupted_images(train_dir)\n",
        "remove_corrupted_images(val_dir)\n",
        "remove_corrupted_images(test_dir)\n",
        "\n",
        "# Now proceed with the ImageDataGenerator\n",
        "train_data = ImageDataGenerator(rescale=1./255)\n",
        "val_data = ImageDataGenerator(rescale=1./255)\n",
        "test_data = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_data.flow_from_directory(train_dir, target_size=(224, 224), batch_size=64, class_mode='categorical')\n",
        "val_gen = val_data.flow_from_directory(val_dir, target_size=(224, 224), batch_size=64, class_mode='categorical')\n",
        "test_gen = test_data.flow_from_directory(test_dir, target_size=(224, 224), batch_size=64, class_mode='categorical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYl5RwoaHcYn",
        "outputId": "92deb061-4651-4447-8b3e-2ae96c78ff86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "364/364 [==============================] - ETA: 0s - loss: 6.9661 - accuracy: 0.1792\n",
            "Epoch 1: val_loss improved from inf to 43.10599, saving model to model_weights.h5\n",
            "364/364 [==============================] - 1353s 4s/step - loss: 6.9661 - accuracy: 0.1792 - val_loss: 43.1060 - val_accuracy: 0.0334\n",
            "Epoch 2/50\n",
            "364/364 [==============================] - ETA: 0s - loss: 1.8937 - accuracy: 0.4344\n",
            "Epoch 2: val_loss improved from 43.10599 to 7.43188, saving model to model_weights.h5\n",
            "364/364 [==============================] - 168s 462ms/step - loss: 1.8937 - accuracy: 0.4344 - val_loss: 7.4319 - val_accuracy: 0.2463\n",
            "Epoch 3/50\n",
            "364/364 [==============================] - ETA: 0s - loss: 1.2193 - accuracy: 0.6273\n",
            "Epoch 3: val_loss improved from 7.43188 to 4.54672, saving model to model_weights.h5\n",
            "364/364 [==============================] - 1163s 3s/step - loss: 1.2193 - accuracy: 0.6273 - val_loss: 4.5467 - val_accuracy: 0.4376\n",
            "Epoch 4/50\n",
            "364/364 [==============================] - ETA: 0s - loss: 0.9162 - accuracy: 0.7178\n",
            "Epoch 4: val_loss did not improve from 4.54672\n",
            "364/364 [==============================] - 572s 2s/step - loss: 0.9162 - accuracy: 0.7178 - val_loss: 4.9048 - val_accuracy: 0.4431\n",
            "Epoch 5/50\n",
            "364/364 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.7834\n",
            "Epoch 5: val_loss improved from 4.54672 to 3.55401, saving model to model_weights.h5\n",
            "364/364 [==============================] - 450s 1s/step - loss: 0.6940 - accuracy: 0.7834 - val_loss: 3.5540 - val_accuracy: 0.5137\n",
            "Epoch 6/50\n",
            "364/364 [==============================] - ETA: 0s - loss: 0.5814 - accuracy: 0.8198\n",
            "Epoch 6: val_loss did not improve from 3.55401\n",
            "364/364 [==============================] - 568s 2s/step - loss: 0.5814 - accuracy: 0.8198 - val_loss: 5.9583 - val_accuracy: 0.4880\n",
            "Epoch 7/50\n",
            "364/364 [==============================] - ETA: 0s - loss: 0.5171 - accuracy: 0.8428\n",
            "Epoch 7: val_loss did not improve from 3.55401\n",
            "364/364 [==============================] - 392s 1s/step - loss: 0.5171 - accuracy: 0.8428 - val_loss: 5.4308 - val_accuracy: 0.4519\n",
            "Epoch 8/50\n",
            "364/364 [==============================] - ETA: 0s - loss: 0.4360 - accuracy: 0.8670\n",
            "Epoch 8: val_loss did not improve from 3.55401\n",
            "364/364 [==============================] - 218s 598ms/step - loss: 0.4360 - accuracy: 0.8670 - val_loss: 5.8520 - val_accuracy: 0.4906\n",
            "Epoch 9/50\n",
            "364/364 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8840\n",
            "Epoch 9: val_loss did not improve from 3.55401\n",
            "364/364 [==============================] - 156s 429ms/step - loss: 0.3818 - accuracy: 0.8840 - val_loss: 4.5923 - val_accuracy: 0.5586\n",
            "Epoch 10/50\n",
            "364/364 [==============================] - ETA: 0s - loss: 0.3230 - accuracy: 0.9005\n",
            "Epoch 10: val_loss did not improve from 3.55401\n",
            "364/364 [==============================] - 143s 392ms/step - loss: 0.3230 - accuracy: 0.9005 - val_loss: 4.7054 - val_accuracy: 0.5686\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=50,\n",
        "    validation_data=val_gen,\n",
        "    callbacks=[checkpoint_cb, EarlyStopping(monitor='val_loss', patience=5)]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lz4GZ2uWnFUn"
      },
      "outputs": [],
      "source": [
        "model.save('final_testing.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(224, 224, 3)\n",
            "1/1 [==============================] - 23s 23s/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
              "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
              "        0.000000e+00, 0.000000e+00, 0.000000e+00, 1.000000e+00,\n",
              "        0.000000e+00, 0.000000e+00, 0.000000e+00, 9.465985e-35,\n",
              "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
              "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
              "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
              "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
              "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
              "        0.000000e+00]], dtype=float32)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "model = tf.keras.models.load_model('final_testing.h5')\n",
        "image = cv2.imread('D:/DEPI/Project/Train/e/6.jpg')\n",
        "image1 = cv2.resize(image, (224,224))\n",
        "print(image1.shape)\n",
        "prediction = model.predict(np.expand_dims(image1, axis=0))\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "Found 23264 images belonging to 37 classes.\n",
            "Predicted Label: 10\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load the trained model\n",
        "#model = tf.keras.models.load_model('final_testing.h5')\n",
        "\n",
        "# Define the image path\n",
        "image_path = 'D:\\DEPI\\Project\\DEPI_proj_dataset/a/6.jpg'\n",
        "\n",
        "# Load the image and resize it to the required input size (224x224 in your case)\n",
        "image = cv2.imread(image_path)\n",
        "image_resized = cv2.resize(image, (224, 224))\n",
        "\n",
        "# Normalize the image (assuming your ImageDataGenerator applied normalization)\n",
        "image_resized = image_resized / 255.0\n",
        "\n",
        "# Expand dimensions to match the input shape of the model (1, 224, 224, 3)\n",
        "image_expanded = np.expand_dims(image_resized, axis=0)\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(image_expanded)\n",
        "\n",
        "# Get the predicted class index\n",
        "predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "# If you used ImageDataGenerator for training, you can access the class indices like this:\n",
        "# Assuming you used ImageDataGenerator for training and it had a `class_indices` attribute\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory('D:/DEPI/Project/Train/', target_size=(224, 224))\n",
        "\n",
        "# Mapping the class index back to the class label\n",
        "class_labels = {v: k for k, v in train_generator.class_indices.items()}  # Reverse the dictionary\n",
        "predicted_label = class_labels[predicted_class_index]\n",
        "\n",
        "# Display the predicted label\n",
        "print(f\"Predicted Label: {predicted_label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOAe93bRHQqV",
        "outputId": "6dc95e29-4467-48ed-c27e-1e3d3dff6c02"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:454: UserWarning: A total of 7 objects could not be loaded. Example error message for object <Conv2D name=conv2d, built=True>:\n",
            "\n",
            "Layer 'conv2d' expected 2 variables, but received 0 variables during loading. Expected: ['kernel', 'bias']\n",
            "\n",
            "List of objects that could not be loaded:\n",
            "[<Conv2D name=conv2d, built=True>, <BatchNormalization name=batch_normalization, built=True>, <Conv2D name=conv2d_1, built=True>, <BatchNormalization name=batch_normalization_1, built=True>, <Conv2D name=conv2d_2, built=True>, <BatchNormalization name=batch_normalization_2, built=True>, <Dense name=dense, built=True>]\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# model.load_weights('/content/drive/MyDrive/Sign Language Recognition_DEPI/weights/model_weights.weights.h5')\n",
        "\n",
        "\n",
        "# Load the model weights with mismatched layers skipped\n",
        "# Load the model weights with mismatched layers skipped\n",
        "model.load_weights('/content/drive/MyDrive/Sign Language Recognition_DEPI/weights/model_weights.weights.h5',\n",
        "                   skip_mismatch=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYbgcuJ5IhJ0",
        "outputId": "da51fe1b-f84c-4e56-993e-3615a780e139"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17/17 [==============================] - 31s 2s/step - loss: 0.2801 - accuracy: 0.9503\n",
            "Test accuracy: 0.9503\n",
            "Test loss: 0.2801\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_gen)\n",
        "print(f'Test accuracy: {test_acc:.4f}')\n",
        "print(f'Test loss: {test_loss:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PF7QsrEIi0d",
        "outputId": "9a5c7131-0680-46e5-8f42-f007b69e5b62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['.config', 'drive', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.listdir('.'))  # Lists all files in the current directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwggnDw1J-K1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Path to save weights\n",
        "weights_dir = '/content/drive/MyDrive/Sign Language Recognition_DEPI/weights'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "-kOtrhuIKEA7",
        "outputId": "fd5f863a-14e1-4c89-9fd8-a2606698cc28"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_generator' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c4d1f177051f>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train the model for a few epochs to verify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"
          ]
        }
      ],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model for a few epochs to verify\n",
        "model.fit(train_generator, epochs=2, validation_data=validation_generator)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
